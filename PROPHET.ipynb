{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "3uhhz6g22qk3twxjsqc7",
   "authorId": "2289903666435",
   "authorName": "RRAMANI",
   "authorEmail": "rohan.ramani@creditgenie.com",
   "sessionId": "6f1d3dcc-0fa1-4bd8-acab-476d4985e1fe",
   "lastEditTime": 1752170564637
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "SELECT *\nFROM CREDITGENIE.DDB_PROD.PLAIDTRANSACTION \nWHERE plaidaccountid IN (select plaidaccountid from creditgenie.ddb_prod.decision where cast(createdat as date) = '2025-04-01' and iseligible = True limit 100)\nand TRANSACTIONDATE > '2025-01-01'\nand is_pending = FALSE\norder by transactiondate desc",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "df = cell2.to_pandas()\nnumeric_cols = df.select_dtypes(include='number').columns\ndf[numeric_cols] = -df[numeric_cols]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "15a69ef8-c5b8-4b10-a60e-f619f5e4010a",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark import Session\nresult3 = df['PLAIDACCOUNTID']\n\nsession = get_active_session()\n\nplaidaccountid_list = result3.tolist()\nplaidaccountid_str = ', '.join(f\"'{id}'\" for id in plaidaccountid_list)\n\nquery = f'''\nselect plaidaccountid, AVAILABLE, \"current\", createdat from creditgenie.ddb_prod.plaidaccountbalance b\nwhere b.plaidaccountid in ({plaidaccountid_str})\nand b.createdat between '2025-01-01' and '2025-05-15'\n'''\n\nresult_df3 = session.sql(query)\ndft = result_df3.collect()\ndft = pd.DataFrame(dft)\ndft.columns = [column.lower() for column in dft.columns]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd50ce07-58f8-47e2-bd5a-9741d9c16367",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nfrom prophet import Prophet\nimport optuna\nfrom sklearn.metrics import mean_squared_error\n\n# --- Constants ---\nPREDICTION_START_DATE = pd.to_datetime(\"2025-04-05\")\nMAX_PREDICTION_DATE = pd.to_datetime(\"2025-05-02\")\nyour_threshold = -100\n\n# --- Tune Prophet hyperparameters using Optuna on one sample ID ---\nsample_id = df[\"PLAIDACCOUNTID\"].unique()[0]\ngroup = df[df[\"PLAIDACCOUNTID\"] == sample_id].copy()\n\n# Use transaction data for sample tuning\ndata = group.copy()\ndata[\"DATE\"] = pd.to_datetime(data[\"TRANSACTIONDATE\"])\ndata = data.groupby(\"DATE\").sum(numeric_only=True).reset_index()\ndata.rename(columns={\"DATE\": \"ds\", \"TRANSACTIONAMOUNT\": \"y\"}, inplace=True)\n\n# Restrict to training data only (before 06-05)\ndata = data.sort_values(\"ds\")\ntrain_df_sample = data[data[\"ds\"] <= pd.to_datetime(\"2025-04-04\")]\n\ndef objective(trial):\n    changepoint_prior_scale = trial.suggest_float(\"changepoint_prior_scale\", 0.001, 0.5, log=True)\n    seasonality_prior_scale = trial.suggest_float(\"seasonality_prior_scale\", 0.01, 10.0, log=True)\n    seasonality_mode = trial.suggest_categorical(\"seasonality_mode\", [\"additive\", \"multiplicative\"])\n\n    try:\n        model = Prophet(\n            daily_seasonality=True,\n            weekly_seasonality=True,\n            yearly_seasonality=False,\n            changepoint_prior_scale=changepoint_prior_scale,\n            seasonality_prior_scale=seasonality_prior_scale,\n            seasonality_mode=seasonality_mode\n        )\n        model.fit(train_df_sample)\n\n        future = model.make_future_dataframe(periods=30)\n        forecast = model.predict(future)\n\n        merged = train_df_sample.merge(forecast[[\"ds\", \"yhat\"]], on=\"ds\", how=\"left\")\n\n        holdout_size = int(len(merged) * 0.2)\n        if holdout_size == 0:\n            return float(\"inf\")\n        holdout = merged[-holdout_size:]\n\n        rmse = np.sqrt(mean_squared_error(holdout[\"y\"], holdout[\"yhat\"]))\n        return rmse\n\n    except Exception:\n        return float(\"inf\")\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=30)\n\nbest_params = study.best_params\nprint(\"Best hyperparameters (from sample ID):\", best_params)\n\n# --- Final loop for all IDs ---\nprophet_results = {}\nforecast_dfs = {}\n\nfor plaid_id, group in df.groupby(\"PLAIDACCOUNTID\"):\n    # Get earliest balance from dft\n    group_dft = dft[dft[\"plaidaccountid\"] == plaid_id].copy()\n    group_dft[\"createdat\"] = pd.to_datetime(group_dft[\"createdat\"]).dt.tz_localize(None)\n    group_dft[\"balance_value\"] = group_dft[\"current\"].where(pd.notnull(group_dft[\"current\"]), group_dft[\"available\"])\n    group_dft = group_dft.sort_values(\"createdat\")\n\n    if group_dft.empty or pd.isna(group_dft.iloc[0][\"balance_value\"]):\n        continue\n\n    earliest_balance_value = group_dft.iloc[0][\"balance_value\"]\n    start_date = group_dft.iloc[0][\"createdat\"]\n\n    # Filter transactions data from start_date\n    data = group.copy()\n    data[\"DATE\"] = pd.to_datetime(data[\"TRANSACTIONDATE\"])\n    data = data[data[\"DATE\"] >= start_date]\n\n    if data.empty or len(data) < 20:\n        continue\n\n    # Aggregate daily, sort\n    data = data.groupby(\"DATE\").sum(numeric_only=True).reset_index()\n    data.rename(columns={\"DATE\": \"ds\", \"TRANSACTIONAMOUNT\": \"flow\"}, inplace=True)\n    data = data.sort_values(\"ds\")\n\n    # Create cumulative balance series starting from earliest_balance_value\n    data[\"y\"] = earliest_balance_value + data[\"flow\"].cumsum()\n\n    # Restrict to training data only for model fit\n    train_df = data[data[\"ds\"] <= pd.to_datetime(\"2025-04-04\")]\n\n    if train_df.empty or len(train_df) < 20:\n        continue\n\n    try:\n        model = Prophet(\n            daily_seasonality=True,\n            weekly_seasonality=True,\n            yearly_seasonality=False,\n            changepoint_prior_scale=best_params[\"changepoint_prior_scale\"],\n            seasonality_prior_scale=best_params[\"seasonality_prior_scale\"],\n            seasonality_mode=best_params[\"seasonality_mode\"]\n        )\n        model.fit(train_df)\n\n        num_test_days = (MAX_PREDICTION_DATE - PREDICTION_START_DATE).days + 1\n        future = model.make_future_dataframe(periods=num_test_days)\n        forecast = model.predict(future)\n\n        # Filter only prediction window\n        forecast_future = forecast[\n            (forecast[\"ds\"] >= PREDICTION_START_DATE) &\n            (forecast[\"ds\"] <= MAX_PREDICTION_DATE)\n        ]\n\n        # âœ… Save merged dataframe with ALL actual transactions\n        actuals_df = data[[\"ds\", \"y\"]]\n        merged_df = forecast.merge(actuals_df, on=\"ds\", how=\"left\")\n        forecast_dfs[plaid_id] = merged_df\n\n        below_threshold = forecast_future[\"yhat\"] < your_threshold\n\n        if below_threshold.any():\n            predicted_index = forecast_future[below_threshold][\"ds\"].iloc[0]\n\n            if predicted_index < PREDICTION_START_DATE:\n                predicted_index = PREDICTION_START_DATE\n            if predicted_index > MAX_PREDICTION_DATE:\n                predicted_index = MAX_PREDICTION_DATE\n        else:\n            predicted_index = pd.NaT\n\n    except Exception:\n        predicted_index = pd.NaT\n\n    days_difference = pd.NA  # No actual_date logic now\n\n    prophet_results[plaid_id] = {\n        \"predicted_date\": predicted_index,\n        \"days_difference\": days_difference,\n        \"source\": \"prophet\"\n    }\n\n# --- Final results DataFrame ---\nprophet_results_df = pd.DataFrame([\n    {\n        \"plaidaccountid\": pid,\n        \"predicted_date\": res[\"predicted_date\"],\n        \"days_difference\": res[\"days_difference\"],\n        \"source\": res[\"source\"]\n    }\n    for pid, res in prophet_results.items()\n])\n\nprophet_results_df\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fcd3fe85-d6ff-43c2-977d-1b46fd48ed90",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\n# --- Choose an ID from forecast_dfs to plot ---\nchosen_id = list(forecast_dfs.keys())[31]  # Replace with index of ID\n\ndf_plot = forecast_dfs.get(chosen_id)\n\nif df_plot is not None:\n    # Filter to prediction window: start and end dates\n    df_plot_filtered = df_plot[\n        #(df_plot[\"ds\"] >= PREDICTION_START_DATE) &\n        (df_plot[\"ds\"] <= MAX_PREDICTION_DATE)\n    ]\n\n    plt.figure(figsize=(12, 6))\n    plt.plot(df_plot_filtered[\"ds\"], df_plot_filtered[\"yhat\"], label=\"Predicted balance\", color=\"blue\", linewidth=2)\n    plt.plot(df_plot_filtered[\"ds\"], df_plot_filtered[\"y\"], label=\"Actual balance\", color=\"black\", linewidth=2, alpha=0.7)\n    plt.axvline(PREDICTION_START_DATE, color=\"green\", linestyle=\"--\", label=\"Prediction Start\")\n    plt.axvline(MAX_PREDICTION_DATE, color=\"red\", linestyle=\"--\", label=\"Prediction End\")\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"balance/Day\")\n    plt.title(f\"Predicted vs Actual Balance for ID: {chosen_id}\\n({PREDICTION_START_DATE.date()} to {MAX_PREDICTION_DATE.date()})\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.show()\nelse:\n    print(f\"No forecast data available for ID: {chosen_id}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f6f5159-acb4-4420-9354-13991b6d1633",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "# dft2 = dft[dft['plaidaccountid'] == 'ZVNQqV7boQHL8PE0DoZwf0AvojD3qpCxRqPBY']\n# dft2\n\ndf2 = df[df['PLAIDACCOUNTID'] == 'ZVNQqV7boQHL8PE0DoZwf0AvojD3qpCxRqPBY']\ndf2\n",
   "execution_count": null
  }
 ]
}